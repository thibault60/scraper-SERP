import streamlit as st
import pandas as pd
from github import Github  # veillez Ã  avoir "PyGithub" dans requirements.txt
from serpapi import GoogleSearch
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from io import BytesIO  # pour l'export XLSX

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Gestion des secrets (.streamlit/secrets.toml)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    SERPAPI_KEY = st.secrets["serpapi_key"]
except Exception:
    st.error("âŒ ClÃ© SerpApi manquante dans `.streamlit/secrets.toml`.")
    st.stop()

GITHUB_TOKEN = st.secrets.get("github_token", None)  # facultatif mais â†‘ quota GitHub API

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ParamÃ¨tres UI (sidebar)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ ParamÃ¨tres")
    hl = st.selectbox("Langue (hl)", ["fr", "en", "es", "de", "it"], index=0)
    gl = st.selectbox("Pays (gl)", ["fr", "us", "es", "de", "it"], index=0)
    max_workers = st.slider("Threads simultanÃ©s", min_value=1, max_value=16, value=8)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Lecture de queries.txt depuis GitHub (public)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GITHUB_REPO = "thibault60/scraper-SERP"  # modifiez si vous forkez
QUERY_FILE = "queries.txt"

github = Github(GITHUB_TOKEN) if GITHUB_TOKEN else Github()
try:
    repo = github.get_repo(GITHUB_REPO)
    contents = repo.get_contents(QUERY_FILE)
    raw_txt = requests.get(contents.download_url).text
    queries = [line.strip() for line in raw_txt.splitlines() if line.strip()]
except Exception as e:
    st.error(f"Impossible de lire `{QUERY_FILE}` depuis le dÃ©pÃ´tâ€¯: {e}")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Fonction dâ€™extraction des PAA (People Also Ask)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_paa(query: str) -> list[dict]:
    """Interroge SerpApi et renvoie la liste des blocs PAA."""
    params = {
        "q": query,
        "api_key": SERPAPI_KEY,
        "hl": hl,
        "gl": gl,
        "num": 10,
    }
    search = GoogleSearch(params)
    results = search.get_dict()
    return results.get("related_questions", [])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Collecte parallÃ¨le + cache
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_paa_single(query: str) -> list[dict]:
    """RÃ©cupÃ¨re les PAA pour une requÃªte donnÃ©e et retourne une liste de dicts."""
    try:
        paa_items = get_paa(query)
        if paa_items:
            return [
                {
                    "RequÃªte": query,
                    "Question PAA": item.get("question", "â€”"),
                    "RÃ©ponse": item.get("snippet") or item.get("answer") or "â€”",
                    "Source": item.get("link", ""),
                }
                for item in paa_items
            ]
        # Pas de PAA
        return [
            {
                "RequÃªte": query,
                "Question PAA": "â€”",
                "RÃ©ponse": "â€”",
                "Source": "",
            }
        ]
    except Exception as exc:
        return [
            {
                "RequÃªte": query,
                "Question PAA": "â€”",
                "RÃ©ponse": f"Erreurâ€¯: {exc}",
                "Source": "",
            }
        ]

@st.cache_data(ttl=86_400, show_spinner=False)
def fetch_paa_parallel(queries_list: list[str], workers: int) -> pd.DataFrame:
    """Collecte les PAA en parallÃ¨le avec une barre de progression."""
    rows: list[dict] = []
    progress = st.progress(0.0, text="ğŸ”„ RÃ©cupÃ©ration des PAAÂ â€¦")
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(fetch_paa_single, q): q for q in queries_list}
        total = len(futures)
        for i, future in enumerate(as_completed(futures), 1):
            rows.extend(future.result())
            progress.progress(i / total)
    progress.empty()
    return pd.DataFrame(rows)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Interface Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="Scraper PAA SERP", layout="wide")
st.title("ğŸ¤– Extraction des PAA Google â€“ scraper-SERP")
st.markdown(
    "Cette application lit `queries.txt` depuis GitHub, interroge SerpApi et affiche les blocs **People Also Ask** (PAA)."
)

if st.button("ğŸ•¹ï¸ Extraire les PAA"):
    df_paa = fetch_paa_parallel(queries, max_workers)

    st.dataframe(
        df_paa,
        use_container_width=True,
        height=600,
        column_order=["RequÃªte", "Question PAA", "RÃ©ponse", "Source"],
    )

    # TÃ©lÃ©chargement CSV
    csv = df_paa.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ğŸ’¾ TÃ©lÃ©charger le CSV",
        data=csv,
        file_name="paa_results.csv",
        mime="text/csv",
    )

    # TÃ©lÃ©chargement XLSX
    xlsx_buffer = BytesIO()
    with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:  # nÃ©cessite `xlsxwriter` dans requirements.txt
        df_paa.to_excel(writer, index=False, sheet_name="PAA")
    xlsx_buffer.seek(0)
    st.download_button(
        label="ğŸ“Š TÃ©lÃ©charger le XLSX",
        data=xlsx_buffer,
        file_name="paa_results.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    # Affichage dÃ©taillÃ© (groupÃ© par requÃªte)
    for query in df_paa["RequÃªte"].unique():
        subset = df_paa[df_paa["RequÃªte"] == query]
        with st.expander(f"ğŸ” {query} â€” {len(subset)} questions"):
            for _, r in subset.iterrows():
                st.markdown(f"**QÂ :** {r['Question PAA']}")
                if r["RÃ©ponse"] not in ("â€”", ""):
                    st.markdown(r["RÃ©ponse"])
                if r["Source"]:
                    st.caption(r["Source"])
                st.markdown("---")
